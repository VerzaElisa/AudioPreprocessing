{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import ReLU\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.multiprocessing\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from torch import optim\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from colorama import Fore\n",
    "from IPython.display import Audio, display\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import psutil\n",
    "\n",
    "#log setup\n",
    "writer_path = os.path.join('runs', 'logger_classifier')\n",
    "os.makedirs(writer_path, exist_ok=True)\n",
    "writer = SummaryWriter(writer_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definizione delle variabili globali principali.\n",
    "I wokers sono i thread paralleli che caricano i batch del dataset nelle varie epoche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "DATASET_PATH = os.path.join(\"..\", \"spectrograms\")\n",
    "IMAGE_SIZE = (839, 351)\n",
    "CHANNEL_COUNT = 3\n",
    "ACCURACY_THRESHOLD = 85\n",
    "MAX_EPOCHS = 300\n",
    "LEARNING_RATE = 0.01\n",
    "GRADIENT_MOMENTUM = 0.90\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene caricato il dataset. datasets.ImageFolder Ã¨ un metodo di pytorch che carica il dataset sapendo che le immagini sono divise in classi a seconda del nome della cartella in cui sono contenute, viene anche specificato cosa fare dei dati caricati, ovvero una trasformazione in tensore.\n",
    "Infine viene fatto lo split tra train e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformation\n",
    "transform=transforms.ToTensor() \n",
    "\n",
    "# Load the dataset\n",
    "print(Fore.LIGHTMAGENTA_EX + f\"Loading images from dataset at {DATASET_PATH}\")\n",
    "dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)\n",
    "\n",
    "# train / test split\n",
    "val_ratio = 0.2\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "print(Fore.GREEN + f\"{train_size} images for training, {val_size} images for validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisione in batch di train e validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Load into batches\n",
    "train_batches = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=NUM_WORKERS,\n",
    "                                           pin_memory=False) # switch to True if using collate\n",
    "\n",
    "val_batches = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size*2,\n",
    "                                         num_workers=NUM_WORKERS,\n",
    "                                         pin_memory=False) # switch to True if using collate\n",
    "\n",
    "print(Fore.LIGHTMAGENTA_EX + f\"Dataset loaded in batches.\")\n",
    "print(Fore.GREEN + f\"Batch set to {batch_size} for training\")\n",
    "print(Fore.GREEN + f\"Batch set to {batch_size*2} for validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definizione della rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN as sequential\n",
    "class neuralNetworkV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1) \n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1) \n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(10, 10, kernel_size=3, stride=2, padding=1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(in_features=780, out_features=50)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pooling(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pooling(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.flatten(x)\n",
    "        try:\n",
    "            x = self.linear(x)\n",
    "        except Exception as e:\n",
    "            print(Fore.RED + f\"Error : Linear block should take support shape of {x.shape} for in_features.\")\n",
    "        return x\n",
    "\n",
    "selected_model = neuralNetworkV1()\n",
    "train_images_sample, _ = next(iter(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fore.LIGHTMAGENTA_EX + \"Model summary : \" + Fore.GREEN)\n",
    "print(summary(selected_model, (CHANNEL_COUNT, IMAGE_SIZE[0], IMAGE_SIZE[1])))\n",
    "writer.add_graph(selected_model, train_images_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni di utility per l'addestramento della rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display total time training\n",
    "def display_training_time(start, end, device):\n",
    "    total_time = end - start\n",
    "    print(Fore.LIGHTMAGENTA_EX + f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "# Calculate accuracy\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "# Display training infos for each epochs\n",
    "def display_training_infos(epoch, val_loss, train_loss, accuracy):\n",
    "    val_loss = round(val_loss.item(), 3)\n",
    "    train_loss = round(train_loss.item(), 3)\n",
    "    accuracy = round(accuracy, 2)\n",
    "    print(Fore.GREEN + f\"Epoch : {epoch}, Training loss : {train_loss}, Validation loss : {val_loss}, Accuracy : {accuracy} %\")\n",
    "\n",
    "# Check memory usage excess\n",
    "def check_memory():\n",
    "    mem_percent = psutil.virtual_memory().percent\n",
    "    swap_percent = psutil.swap_memory().percent\n",
    "    if mem_percent >= 90:\n",
    "        print(Fore.YELLOW + f\"WARNING : Reached {mem_percent} memory usage !\")\n",
    "        os.system(f'say \"Memory usage high\"')\n",
    "    if swap_percent >= 90:\n",
    "        print(Fore.YELLOW + f\"WARNING : Reached {mem_percent} memory usage !\")\n",
    "        os.system(f'say \"Swap usage high\"')\n",
    "    if mem_percent >= 95 and swap_percent >= 95:\n",
    "        print(Fore.RED + f\"ABORTING : Memory and Swap full !\")\n",
    "        os.system(f'say \"Aborting training\"')\n",
    "        raise MemoryError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training della rete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(selected_model.parameters(), lr=LEARNING_RATE, momentum=GRADIENT_MOMENTUM)\n",
    "\n",
    "def train_neural_net(epochs, model, loss_func, optimizer, train_batches, val_batches):\n",
    "    last_loss = 0\n",
    "    final_accuracy = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # check memory and swap usage\n",
    "        check_memory()\n",
    "        # training mode\n",
    "        model.train()\n",
    "        with torch.enable_grad():\n",
    "            train_loss = 0\n",
    "            for images, labels in train_batches:\n",
    "                predictions = model(images)\n",
    "                loss = loss_func(predictions, labels)\n",
    "                train_loss += loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            train_loss /= len(train_batches)\n",
    "            writer.add_scalar(\"training loss\", train_loss, epoch)\n",
    "        # evaluation mode\n",
    "        val_loss, val_accuracy = 0, 0\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for images, labels in val_batches:\n",
    "                predictions = model(images)\n",
    "                val_loss += loss_func(predictions, labels)\n",
    "                val_accuracy += accuracy_fn(y_true=labels, y_pred=predictions.argmax(dim=1))\n",
    "            val_loss /= len(val_batches)\n",
    "            val_accuracy /= len(val_batches)\n",
    "            writer.add_scalar(\"validation loss\", val_loss, epoch)\n",
    "            final_accuracy = val_accuracy\n",
    "        display_training_infos(epoch+1, val_loss, train_loss, val_accuracy)\n",
    "        writer.add_scalar(\"accuracy\", val_accuracy, epoch)\n",
    "        if val_accuracy >= ACCURACY_THRESHOLD:\n",
    "            break\n",
    "        last_loss = val_loss\n",
    "    return final_accuracy\n",
    "\n",
    "print(Fore.LIGHTMAGENTA_EX + \"Model ready : \")\n",
    "print(Fore.GREEN, f\"Learning rate set to : {LEARNING_RATE}\")\n",
    "print(Fore.GREEN, f\"Momentum set to : {GRADIENT_MOMENTUM}\")\n",
    "\n",
    "print(Fore.LIGHTMAGENTA_EX + \"Starting model training...\")\n",
    "train_time_start_on_gpu = timer()\n",
    "training_complete = False\n",
    "model_accuracy = train_neural_net(MAX_EPOCHS, selected_model, loss_func, optimizer, train_batches, val_batches)\n",
    "print(Fore.LIGHTCYAN_EX + f\"Training complete : {model_accuracy} %\")\n",
    "os.system(f'say \"Training complete\"')\n",
    "training_complete = True\n",
    "display_training_time(start=train_time_start_on_gpu,\n",
    "                  end=timer(),\n",
    "                  device=compute_unit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
